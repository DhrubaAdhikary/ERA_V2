{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 16 02:27:06 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.17              Driver Version: 550.54.17      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   29C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SkalskiP/yolov9.git\n",
    "!pip install -r \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/requirements.txt\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/gelan-c.pt'], source=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/tumor/images/volume_1_slice_34.jpg, data=../yolov9-main/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../yolov9-main/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 2024-5-15 Python-3.12.3 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 14918MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 467 layers, 25472640 parameters, 0 gradients, 102.8 GFLOPs\n",
      "image 1/1 /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/tumor/images/volume_1_slice_34.jpg: 608x640 1 potted plant, 1 vase, 88.5ms\n",
      "Speed: 0.6ms pre-process, 88.5ms inference, 127.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov9-main/runs/detect/exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/detect.py\" \\\n",
    "    --weights \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/gelan-c.pt\" \\\n",
    "        --conf 0.1 \\\n",
    "            --source \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/tumor/images/volume_1_slice_34.jpg\" \\\n",
    "                --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/runs/train/yolov9-c-leaves2/weights/best.pt, cfg=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/models/detect/yolov9-c.yaml, data=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/data/leaves.yaml, hyp=hyp.scratch-high.yaml, epochs=10, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../yolov9-main/runs/train, name=yolov9-c-leaves, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5 🚀 2024-5-15 Python-3.12.3 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 14918MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../yolov9-main/runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.Silence                   []                            \n",
      "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  8                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
      " 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
      " 17                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
      " 20                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  \n",
      " 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             \n",
      " 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        \n",
      " 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      " 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      " 29                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
      " 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      " 32                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
      " 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 35                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
      " 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 38[31, 34, 37, 16, 19, 22]  1  21549752  models.yolo.DualDDetect                 [4, [512, 512, 512, 256, 512, 512]]\n",
      "yolov9-c summary: 962 layers, 51006520 parameters, 51006488 gradients, 238.9 GFLOPs\n",
      "\n",
      "Transferred 1460/1460 items from /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/runs/train/yolov9-c-leaves2/weights/best.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/leave\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/leaves_\u001b[0m\n",
      "Plotting labels to ../yolov9-main/runs/train/yolov9-c-leaves3/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m../yolov9-main/runs/train/yolov9-c-leaves3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        0/9      3.03G      1.549      1.387      2.324          4        640:  WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
      "        0/9      3.45G      1.129      1.024       1.92          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.976      0.936      0.985      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/9      3.46G      1.137     0.9991      1.904          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.938      0.967      0.995      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/9      3.46G      1.175      1.015       1.95          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.949      0.966      0.995      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/9      3.46G      1.195      1.042      1.982          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.951      0.997      0.995      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/9      3.46G      1.186      1.103      1.959          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.978      0.921      0.974      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/9      3.46G      1.183      1.082      1.967          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.964      0.946      0.991      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        6/9      3.46G      1.158      0.972      1.912          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.899      0.909      0.964      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        7/9      3.46G      1.154      1.027      1.919          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.952      0.898      0.944      0.707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        8/9      3.46G      1.152     0.9891      1.914          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.965      0.905      0.953      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        9/9      3.46G      1.111     0.9681      1.878          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.981      0.881      0.965      0.731\n",
      "\n",
      "10 epochs completed in 0.224 hours.\n",
      "Optimizer stripped from ../yolov9-main/runs/train/yolov9-c-leaves3/weights/last.pt, 102.8MB\n",
      "Optimizer stripped from ../yolov9-main/runs/train/yolov9-c-leaves3/weights/best.pt, 102.8MB\n",
      "\n",
      "Validating ../yolov9-main/runs/train/yolov9-c-leaves3/weights/best.pt...\n",
      "Fusing layers... \n",
      "yolov9-c summary: 724 layers, 50965560 parameters, 0 gradients, 237.7 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         30         30      0.938      0.967      0.995      0.749\n",
      "                  CVPD         30          7          1      0.867      0.995      0.521\n",
      "                Kanker         30         11       0.97          1      0.995      0.861\n",
      "             Melanosis         30          2      0.813          1      0.995      0.846\n",
      "                 Sehat         30         10      0.971          1      0.995      0.769\n",
      "Results saved to \u001b[1m../yolov9-main/runs/train/yolov9-c-leaves3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train yolov9 models on leaves dataset\n",
    "!python \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/train_dual.py\" \\\n",
    "    --workers 8 --device 0 --batch 2 \\\n",
    "        --data \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/data/leaves.yaml\" --img 640 \\\n",
    "            --cfg \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/models/detect/yolov9-c.yaml\" \\\n",
    "                --weights '/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/yolov9-e.pt' \\\n",
    "                    --name yolov9-c-leaves \\\n",
    "                        --hyp hyp.scratch-high.yaml \\\n",
    "                            --min-items 0 \\\n",
    "                                --epochs 300 \\\n",
    "                                    --close-mosaic 15\n",
    "\n",
    "#restart training fro last checkpoint \n",
    "# train yolov9 models on leaves dataset\n",
    "# !python \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/train_dual.py\" \\\n",
    "#     --workers 8 --device 0 --batch 2 \\\n",
    "#         --data \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/data/leaves.yaml\" --img 640 \\\n",
    "#             --cfg \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/models/detect/yolov9-c.yaml\" \\\n",
    "#                 --weights '/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/runs/train/yolov9-c-leaves2/weights/best.pt' \\\n",
    "#                     --name yolov9-c-leaves \\\n",
    "#                         --hyp hyp.scratch-high.yaml \\\n",
    "#                             --min-items 0 \\\n",
    "#                                 --epochs 10 \\\n",
    "#                                     --close-mosaic 15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir ../yolov9-main/runs/train --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/yolov9-e.pt, cfg=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/models/detect/yolov9-c.yaml, data=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/data/tumor.yaml, hyp=hyp.scratch-high.yaml, epochs=50, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../yolov9-main/runs/train, name=yolov9-c-tumor, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5 🚀 2024-5-15 Python-3.12.3 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 14918MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../yolov9-main/runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.Silence                   []                            \n",
      "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  8                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
      " 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
      " 17                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
      " 20                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  \n",
      " 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             \n",
      " 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        \n",
      " 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      " 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      " 29                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
      " 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      " 32                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
      " 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 35                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
      " 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      " 38[31, 34, 37, 16, 19, 22]  1  21542822  models.yolo.DualDDetect                 [1, [512, 512, 512, 256, 512, 512]]\n",
      "yolov9-c summary: 962 layers, 50999590 parameters, 50999558 gradients, 238.9 GFLOPs\n",
      "\n",
      "Transferred 472/1460 items from /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/yolov9-e.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/Tumor\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/Tumor_y\u001b[0m\n",
      "Plotting labels to ../yolov9-main/runs/train/yolov9-c-tumor/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m../yolov9-main/runs/train/yolov9-c-tumor\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       0/49      3.04G      3.761      4.127      5.391          6        640:  WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
      "       0/49      3.27G      4.562      6.097      5.316          0        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0533    0.00978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/49      3.46G      4.537      5.551      5.449          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0446    0.00986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/49      3.46G      4.649      5.368      5.473          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0145     0.0062\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/49      3.46G      4.553      5.469      5.435          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0165     0.0065\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/49      3.46G      4.532      5.947      5.366          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0138    0.00691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/49      3.46G      4.551      5.614      5.399          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0138    0.00691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/49      3.46G      4.491      5.343      5.513          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00222        0.4     0.0204    0.00722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/49      3.46G      4.407      5.261      5.502          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0021        0.2    0.00176   0.000553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/49      3.46G      4.188      5.321      5.521          5        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00494        0.2    0.00397    0.00119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/49      3.46G      4.738      5.315      5.442          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00284        0.4    0.00189   0.000905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/49      3.46G      4.947      6.376      5.617          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/49      3.46G      4.874      5.765      5.609          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/49      3.46G      4.466      5.578      5.575          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0365        0.2      0.017    0.00481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/49      3.46G      4.391      5.282      5.618          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0261        0.2       0.01     0.0039\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/49      3.46G      4.506      5.762      5.414          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.344        0.4       0.16     0.0409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/49      3.46G      4.686       6.48      5.657          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.037        0.2     0.0109    0.00412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/49      3.46G       4.39      5.442      5.584          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.037        0.2     0.0109    0.00412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/49      3.46G      4.708      4.986      5.496          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0159        0.2    0.00939    0.00362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/49      3.46G      4.734      5.399      5.542         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.016        0.8     0.0197    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/49      3.46G      4.483      5.462      5.445          0        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00935        0.6     0.0127     0.0069\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/49      3.46G      4.137      5.647      5.305          5        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0073        0.4    0.00702    0.00227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/49      3.46G       4.39      5.068      5.587          7        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0194        0.4     0.0217     0.0055\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/49      3.46G      4.505      5.424      5.444          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0348        0.2     0.0165    0.00616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/49      3.46G      4.511      4.837      5.557          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0644        0.2     0.0418     0.0158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/49      3.46G      4.751      5.025      5.537          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0452        0.4     0.0425     0.0103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/49      3.46G      4.323      4.741      5.427          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.138        0.4      0.103     0.0183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/49      3.46G      4.534      5.142      5.517          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0431        0.2      0.229     0.0504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/49      3.46G      4.614      5.172      5.582          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0431        0.2      0.229     0.0504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/49      3.46G      4.262      4.987      5.607          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0326        0.6     0.0323    0.00779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/49      3.46G      4.517      5.061      5.566          8        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0157        0.8     0.0174    0.00453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/49      3.46G      4.581      5.016      5.464         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.026        0.4     0.0234    0.00685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/49      3.46G      4.601      5.277      5.495          4        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0378        0.4     0.0289    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/49      3.46G      4.515      5.065      5.481          6        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0367        0.4     0.0273    0.00726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/49      3.46G      4.245      4.779      5.479         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0801        0.4     0.0866     0.0182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/49      3.46G      4.556      5.199      5.419          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5       0.28        0.2      0.116      0.019\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/49      3.46G      4.229      5.397      5.463          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0255        0.2     0.0209    0.00674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/49      3.46G      3.963      5.369      5.554          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0603        0.4      0.042    0.00875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/49      3.46G      3.691      4.905      5.433          3        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0603        0.4      0.042    0.00875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/49      3.46G      3.847      5.585      5.519          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0352        0.2     0.0262    0.00956\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/49      3.46G      4.336      5.849      5.585          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1     0.0265     0.0102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/49      3.46G        4.1      5.628      5.307          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1     0.0235     0.0067\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/49      3.46G      4.179      5.977      5.506          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0623        0.2     0.0446    0.00998\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/49      3.46G      3.781      5.116      5.507          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5     0.0404        0.4     0.0707     0.0142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/49      3.46G      3.973      5.349      5.484          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.797        0.2      0.248     0.0523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/49      3.46G      3.664       5.23      5.388          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1      0.093     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/49      3.46G       3.88      5.637       5.36          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00731          1      0.212     0.0247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/49      3.46G      4.232      5.971      5.419          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1      0.132     0.0174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/49      3.46G      3.874      5.441      5.356          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1      0.059    0.00963\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/49      3.46G      4.373      5.854      5.416          2        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1      0.059    0.00963\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/49      3.46G      4.103      5.738      5.236          1        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5    0.00556          1     0.0674       0.01\n",
      "\n",
      "50 epochs completed in 0.142 hours.\n",
      "Optimizer stripped from ../yolov9-main/runs/train/yolov9-c-tumor/weights/last.pt, 102.8MB\n",
      "Optimizer stripped from ../yolov9-main/runs/train/yolov9-c-tumor/weights/best.pt, 102.8MB\n",
      "\n",
      "Validating ../yolov9-main/runs/train/yolov9-c-tumor/weights/best.pt...\n",
      "Fusing layers... \n",
      "yolov9-c summary: 724 layers, 50958630 parameters, 0 gradients, 237.6 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          3          5      0.802        0.2      0.246     0.0518\n",
      "Results saved to \u001b[1m../yolov9-main/runs/train/yolov9-c-tumor\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train yolov9 models on tumor dataset\n",
    "!python \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/train_dual.py\" \\\n",
    "    --workers 8 --device 0 --batch 2 \\\n",
    "        --data \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/data/tumor.yaml\" --img 640 \\\n",
    "            --cfg \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/models/detect/yolov9-c.yaml\" \\\n",
    "                --weights '/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/yolov9-e.pt' \\\n",
    "                    --name yolov9-c-tumor \\\n",
    "                        --hyp hyp.scratch-high.yaml \\\n",
    "                            --min-items 0 \\\n",
    "                                --epochs 50 \\\n",
    "                                    --close-mosaic 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/runs/train/yolov9-c-leaves3/weights/best.pt'], source=/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/leaves_detection/valid/images/3-png_png.rf.db90132cc40495dabdb16de34fbbc736.jpg, data=../yolov9-main/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../yolov9-main/runs/detect, name=leaf_detect_1, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 2024-5-15 Python-3.12.3 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 14918MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-c summary: 724 layers, 50965560 parameters, 0 gradients, 237.7 GFLOPs\n",
      "image 1/1 /home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/leaves_detection/valid/images/3-png_png.rf.db90132cc40495dabdb16de34fbbc736.jpg: 640x640 1 Sehat, 102.3ms\n",
      "Speed: 0.6ms pre-process, 102.3ms inference, 133.7ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov9-main/runs/detect/leaf_detect_1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python \"/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/detect.py\" \\\n",
    "    --source '/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/S15/leaves_detection/valid/images/3-png_png.rf.db90132cc40495dabdb16de34fbbc736.jpg'\\\n",
    "        --img 640 \\\n",
    "            --device 0 \\\n",
    "                --weights '/home/ec2-user/dhruv_Spain_LLM_UI/Computer_vision_work/yolov9-main/runs/train/yolov9-c-leaves3/weights/best.pt'\\\n",
    "                --name leaf_detect_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dhruv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
