{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary Libraries \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaggle in c:\\users\\danda\\appdata\\roaming\\python\\python39\\site-packages (1.6.14)\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.26.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\danda\\appdata\\roaming\\python\\python39\\site-packages (from kaggle) (2024.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->bleach->kaggle) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\danda\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kaggle\n",
      "Version: 1.6.14\n",
      "Summary: Kaggle API\n",
      "Home-page: https://github.com/Kaggle/kaggle-api\n",
      "Author: Kaggle\n",
      "Author-email: support@kaggle.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\danda\\appdata\\roaming\\python\\python39\\site-packages\n",
      "Requires: tqdm, python-slugify, certifi, six, python-dateutil, bleach, urllib3, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['kaggle']=\"c:\\\\users\\\\danda\\\\appdata\\\\roaming\\\\python\\\\python39\\\\site-packages\\\\kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\danda\\\\.kaggle'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "# Specify the folder where the script should run\n",
    "base_folder = 'D:\\era_v2\\ERA_V2\\S20'\n",
    "\n",
    "# Change current working directory to the base folder\n",
    "os.chdir(base_folder)\n",
    "\n",
    "# Create directory for storing Kaggle API key\n",
    "kaggle_dir = os.path.expanduser('~/.kaggle')  # Default location on Unix-like systems\n",
    "\n",
    "# Check platform and adjust directory path accordingly\n",
    "if platform.system() == 'Windows':\n",
    "    kaggle_dir = os.path.join(base_folder, '.kaggle')\n",
    "elif platform.system() == 'Darwin':  # macOS\n",
    "    kaggle_dir = os.path.join(os.path.expanduser('~'), '.kaggle')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "\n",
    "# Copy the Kaggle API key file\n",
    "try:\n",
    "    shutil.copy('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "except AttributeError:  # Handle Windows\n",
    "    shutil.copy('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "\n",
    "# Set appropriate permissions for the Kaggle API key file\n",
    "try:\n",
    "    os.system('chmod 600 {}'.format(os.path.join(kaggle_dir, 'kaggle.json')))\n",
    "except AttributeError:  # Handle Windows\n",
    "    # On Windows, no need to change permissions\n",
    "    pass\n",
    "\n",
    "# Create directory for dataset download\n",
    "os.makedirs(os.path.join(base_folder, 'corpus'), exist_ok=True)\n",
    "\n",
    "# Download dataset using Kaggle CLI\n",
    "try:\n",
    "    os.system('kaggle datasets download -d furcifer/bangla-newspaper-dataset -p corpus')\n",
    "except FileNotFoundError:\n",
    "    print('Kaggle CLI not found. Please install Kaggle API: https://github.com/Kaggle/kaggle-api')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d furcifer/bangla-newspaper-dataset -p corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file corpus already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# ! mkdir corpus\n",
    "# ! kaggle datasets download -d furcifer/bangla-newspaper-dataset\n",
    "# !kaggle datasets download -d disisbig/hindi-wikipedia-articles-172k\n",
    "# !unzip /content/hindi-wikipedia-articles-172k.zip -d /content/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json(\"/Users/kvzm411/Desktop/ERA V2/ERA_V2/S20/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>category_bn</th>\n",
       "      <th>published_date</th>\n",
       "      <th>modification_date</th>\n",
       "      <th>tag</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>গাজীপুর প্রতিনিধি</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>বাংলাদেশ</td>\n",
       "      <td>০৪ জুলাই ২০১৩, ২৩:২৬</td>\n",
       "      <td>০৪ জুলাই ২০১৩, ২৩:২৭</td>\n",
       "      <td>[গাজীপুর]</td>\n",
       "      <td>0</td>\n",
       "      <td>কালিয়াকৈরে টিফিন খেয়ে ৫০০ শ্রমিক অসুস্থ, বিক...</td>\n",
       "      <td>http://www.prothom-alo.com/bangladesh/article/...</td>\n",
       "      <td>গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায়...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>অনলাইন ডেস্ক</td>\n",
       "      <td>sports</td>\n",
       "      <td>খেলা</td>\n",
       "      <td>০৪ জুলাই ২০১৩, ২৩:০৯</td>\n",
       "      <td>০৪ জুলাই ২০১৩, ২৩:১১</td>\n",
       "      <td>[টেনিস]</td>\n",
       "      <td>0</td>\n",
       "      <td>সেমিফাইনাল বাধাও পেরিয়ে গেলেন লিসিকি</td>\n",
       "      <td>http://www.prothom-alo.com/sports/article/19028</td>\n",
       "      <td>এবারের উইম্বলডনটা স্মরণীয় করে রাখার মিশনেই যে...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author    category category_bn        published_date  \\\n",
       "0  গাজীপুর প্রতিনিধি  bangladesh    বাংলাদেশ  ০৪ জুলাই ২০১৩, ২৩:২৬   \n",
       "1       অনলাইন ডেস্ক      sports        খেলা  ০৪ জুলাই ২০১৩, ২৩:০৯   \n",
       "\n",
       "      modification_date        tag comment_count  \\\n",
       "0  ০৪ জুলাই ২০১৩, ২৩:২৭  [গাজীপুর]             0   \n",
       "1  ০৪ জুলাই ২০১৩, ২৩:১১    [টেনিস]             0   \n",
       "\n",
       "                                               title  \\\n",
       "0  কালিয়াকৈরে টিফিন খেয়ে ৫০০ শ্রমিক অসুস্থ, বিক...   \n",
       "1              সেমিফাইনাল বাধাও পেরিয়ে গেলেন লিসিকি   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.prothom-alo.com/bangladesh/article/...   \n",
       "1    http://www.prothom-alo.com/sports/article/19028   \n",
       "\n",
       "                                             content  \n",
       "0  গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায়...  \n",
       "1  এবারের উইম্বলডনটা স্মরণীয় করে রাখার মিশনেই যে...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['content']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায়...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায়..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the content of the column into a single variable, separated by newline character\n",
    "combined_content = '\\n'.join(df['content'].astype(str).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায় আজ বৃহস্পতিবার রাতের টিফিন খেয়ে একটি পোশাক কারখানার '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_content[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset1 in characters:  820065032\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset1 in characters: \", len(combined_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=combined_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocabulary: 572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "print('Length of Vocabulary:',len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 820065032\n",
      "length of tokens: 2184630568\n"
     ]
    }
   ],
   "source": [
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))\n",
    "print(\"length of text:\", len(text))\n",
    "print(\"length of tokens:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats = get_stats(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((224, 166), 519500466),\n",
       " ((166, 151), 8256353),\n",
       " ((151, 224), 7652319),\n",
       " ((166, 190), 71219243),\n",
       " ((190, 224), 59313647)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stats.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 166)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pair = max(stats, key=stats.get)\n",
    "top_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('à', '¦')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(224), chr(166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "  i = 0\n",
    "  newids = []\n",
    "  while i < len(ids):\n",
    "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "      newids.append(idx)\n",
    "      i += 2\n",
    "    else:\n",
    "      newids.append(ids[i])\n",
    "      i += 1\n",
    "  \n",
    "  return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_merges = len(vocab) - 256\n",
    "num_merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(tokens)\n",
    "merges = {}\n",
    "for i in range(30):\n",
    "  stats = get_stats(ids)\n",
    "  pair = max(stats, key=stats.get)\n",
    "  idx = 256 + i\n",
    "  ids = merge(ids, pair, idx)\n",
    "  merges[pair] = idx\n",
    "\n",
    "print('Merges completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tokens length:\", len(tokens))\n",
    "print(\"ids length:\", len(ids))\n",
    "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('merges.pkl', 'wb') as file:\n",
    "    pickle.dump(merges, file)\n",
    "with open('vocab.pkl', 'wb') as file:\n",
    "    pickle.dump(vocab, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "\n",
    "tokenizer_hindi_pattern=re.compile(r'(['+string.punctuation+r'\\u0964\\u0965\\uAAF1\\uAAF0\\uABEB\\uABEC\\uABED\\uABEE\\uABEF\\u1C7E\\u1C7F'+r'])')\n",
    "pattern_num_seq=re.compile(r'([0-9]+ [,.:/] )+[0-9]+')\n",
    "\n",
    "def tokenize_hindi_text(text): \n",
    "    \"\"\"tokenize string for Indian language scripts using Brahmi-derived scripts\n",
    "\n",
    "    A trivial tokenizer which just tokenizes on the punctuation boundaries. \n",
    "    This also includes punctuations for the Indian language scripts (the \n",
    "    purna virama and the deergha virama). This is a language independent \n",
    "    tokenizer\n",
    "\n",
    "    Args:\n",
    "        text (str): text to tokenize\n",
    "\n",
    "    Returns:\n",
    "        list: list of tokens\n",
    "\n",
    "    \"\"\"\n",
    "    tok_str=tokenizer_hindi_pattern.sub(r' \\1 ',text.replace('\\t',' '))\n",
    "    s=re.sub(r'[ ]+',' ',tok_str).strip(' ')\n",
    "    \n",
    "    # do not tokenize numbers and dates\n",
    "    new_s=''\n",
    "    prev=0\n",
    "    for m in pattern_num_seq.finditer(s):\n",
    "        start=m.start()\n",
    "        end=m.end()\n",
    "        if start>prev:\n",
    "            new_s=new_s+s[prev:start]\n",
    "            new_s=new_s+s[start:end].replace(' ','')\n",
    "            prev=end\n",
    "   \n",
    "    new_s=new_s+s[prev:]\n",
    "    s=new_s\n",
    "    \n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_hindi_text('সেমিফাইনাল বাধাও পেরিয়ে গেলেন লিসিকি')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
